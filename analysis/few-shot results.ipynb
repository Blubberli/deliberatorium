{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run base.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'few-shot-seeds-mulneg'\n",
    "experiment = 'more-few-shot-seeds'\n",
    "# experiment = 'more-batch64-few-shot-seeds'\n",
    "# experiment = 'more-epochs-few-shot-seeds'\n",
    "# experiment = 'moreepochs5-few-shot-seeds'\n",
    "# experiment = 'more-few-shot-all-meaningless-seeds'\n",
    "# experiment = 'templates0.1-few-shot-seeds'\n",
    "# experiment = 'templates0.2-few-shot-seeds'\n",
    "# experiment = 'templates0.2-seeds'\n",
    "\n",
    "with_samples = False\n",
    "# with_samples = True\n",
    "\n",
    "results_path = get_experiment_path(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'mpnet'\n",
    "model = 'all-mpnet'\n",
    "# model = 'all-mini'\n",
    "extra = ''\n",
    "# extra = 'epoch2'\n",
    "# extra = 'epoch3'\n",
    "# extra = 'epoch5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def format_f(x):\n",
    "    return re.sub('^0\\.', '.', f'{x:.4f}')\n",
    "\n",
    "regex = f'{model}.*{extra}-?([a-zA-Z_]*)?(?:-n(\\d+)in(\\d+))?-seed(\\d+)'\n",
    "regex = f'{model}.*{extra}-([a-zA-Z_]*)?(?:-n(\\d+)in(\\d+))?-seed(\\d+)'\n",
    "\n",
    "def read_results(name, templates=[]):\n",
    "    extra_cols = ['per_map_size', 'map_size'] if 'few-shot' in experiment else []\n",
    "    \n",
    "    folder = f'{model}*{extra}*' if extra else f'{model}*'\n",
    "    paths = list(results_path.glob(f'{folder}/results/{name}.json'))\n",
    "    dfs = []\n",
    "    for path in tqdm(paths):\n",
    "#         print(path)\n",
    "        df = pd.read_json(path, orient='index')\n",
    "        if len(df.columns) == 1:\n",
    "            df = pd.DataFrame([df.to_dict()[0]], columns=df.to_dict()[0].keys())\n",
    "#         df[['model','template','per_map_size', 'map_size', 'seed']] = re.findall(r'([a-zA-Z]+-[a-zA-Z]+)-([a-zA-Z_]*)-n(\\d+)in(\\d+).*seed(\\d+)', str(path))\n",
    "#         df[['template','per_map_size', 'map_size', 'seed']] = re.findall(f'-([a-zA-Z_]*)-n(\\d+)in(\\d+).*seed(\\d+)', str(path).replace('all-meaningless', 'all_meaningless'))\n",
    "        df[['template','per_map_size', 'map_size', 'seed']] = re.findall(regex, str(path).replace('all-meaningless', 'all_meaningless').replace('all-all', 'all_all'))\n",
    "#         print(df)\n",
    "        df[extra_cols+['seed']] = df[extra_cols+['seed']].apply(lambda x: int(x))\n",
    "\n",
    "#         display(df)\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df.loc[df['template']=='mulneg', 'template']='none'\n",
    "    df.loc[df['template']=='', 'template']='none'\n",
    "    ordered_templates = ['none', 'beginning', 'foo', 'pro_con', 'combined', 'all', 'all_meaningless']\n",
    "    ordered_templates = ['none', 'beginning', 'pro_con', 'all', 'all_meaningless', 'all_all']\n",
    "#     df = df.sort_values(by=['template'], key=lambda x: x.map({k:v for k,v in zip(ordered_templates, list(range(len(ordered_templates))))}))\n",
    "#     display(df)\n",
    "    df = pd.pivot_table(df, index=extra_cols+['template'], values=['p1', 'p5', 'mrr'],\n",
    "                                aggfunc=[np.mean, np.std, np.count_nonzero], dropna=False)\n",
    "    df = df[df['count_nonzero']['p1']==5]\n",
    "    # display(df)\n",
    "\n",
    "    formatter = lambda x: (x[0] if type(x[0])==str else format_f(x[0])+(f'\\u00B1{format_f(x[1])}' if not pd.isna(x[1]) else '').replace('%',''))\n",
    "    f_df = pd.DataFrame({col: zip(df['mean'][col], df['std'][col]) for col in df['mean'].columns})\n",
    "    f_df.index = df.index\n",
    "    f_df = f_df.applymap(formatter)\n",
    "    \n",
    "    f_df = f_df[['p1', 'p5', 'mrr']]\n",
    "#     f_df.reset_index(level=0, inplace=True)\n",
    "#     f_df.columns = f_df.columns.droplevel(2)\n",
    "    \n",
    "#     if not 'epoch' in extra:\n",
    "    if extra_cols:\n",
    "        f_df = f_df.reindex(ordered_templates, level=2)\n",
    "    else:\n",
    "        f_df = f_df.reindex(ordered_templates)\n",
    "    \n",
    "    return f_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with/without samples results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regex)\n",
    "path = '/home/ij/data/delib-results/results/moreepochs5-few-shot-seeds/all-mpnet-mulneg-epoch5-n16in32-seed13/results/avg.json'\n",
    "re.findall(regex, str(path).replace('all-meaningless', 'all_meaningless'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_samples:\n",
    "    df = pd.concat([read_results('avg'), read_results('annotated_samples_metrics')], keys=['test', 'samples'], axis=1)\n",
    "    # df.columns = results_df.columns.droplevel(0)\n",
    "    # df.reset_index(level=0)\n",
    "else:\n",
    "    df = read_results('avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_latex(df):\n",
    "#     df = df.reset_index(level=0)\n",
    "#     df = df.reset_index(level=0)\n",
    "#     display(df)\n",
    "    \n",
    "#     df['per_map_size x map_size'] = df.apply(lambda x: f\"{x['per_map_size']} x {x['map_size']}\", axis=1)\n",
    "#     df = df.drop(['per_map_size', 'map_size'], axis=1)\n",
    "    return (df\n",
    "            .applymap(lambda x: '$'+'_{\\pm'.join(x.split('\\u00B1'))+'}$' if '\\u00B1' in x else x)            \n",
    "#             .style.highlight_max().to_latex(escape=False)\n",
    "            .to_latex(escape=False)\n",
    "            .replace('per_map_size', '\\#nodes').replace('map_size', '\\#maps'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Few-shot Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "sizes = [8, 16, 32, 64]\n",
    "\n",
    "summary_df = df.query(\"template in ['none', 'beginning', 'pro_con', 'all']\")\n",
    "summary_df = df.query(\"template in ['none', 'beginning', 'foo', 'pro_con', 'all', 'all_meaningless']\")\n",
    "if 'few-shot' in experiment:\n",
    "    summary_df = pd.concat([summary_df.query(f'per_map_size == {x} and map_size == {x}') for x in sizes])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_with_latex_mathbf(s):\n",
    "    print(s)\n",
    "    print(s.replace(' $', ' $\\mathbf{').replace('_{', '}_{'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_with_latex_mathbf(to_latex(summary_df).replace('beginning', 'parent/child').replace('pro_con', 'pro/con'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered Results (Foobar etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_df = df.query(\"template in ['beginning', 'foo']\")\n",
    "foo_df = df.query(\"template in ['all']\")\n",
    "# foo_df = df.query(\"template in ['none']\")\n",
    "# foo_df = df.query(\"template in ['all', 'all_meaningless']\")\n",
    "foo_df = pd.concat([foo_df.query(f'per_map_size == {x} and map_size == {x}') for x in sizes])\n",
    "foo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_latex(foo_df).replace('beginning', 'parent/child').replace('foo', 'foo/bar').replace('all_meaningless', 'all meaningless'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_with_latex_mathbf(to_latex(foo_df.reset_index(level=2, drop=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #nodes vs #maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_related_sizes = list(dict.fromkeys(itertools.chain.from_iterable([(x, y), (y, x)] for x, y in itertools.product(sizes, sizes) if x != y)))\n",
    "related_df = df.query(\"template == 'none'\")\n",
    "related_df = pd.concat([related_df.query(f'per_map_size == {x} and map_size == {y}') for x, y in ordered_related_sizes])\n",
    "related_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_latex(related_df.reset_index(level=2, drop=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
